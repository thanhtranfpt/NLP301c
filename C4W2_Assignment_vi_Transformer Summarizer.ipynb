{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05014ac7",
   "metadata": {
    "colab_type": "text",
    "id": "7yuytuIllsv1"
   },
   "source": [
    "\n",
    "# Bài 2: Tóm tắt máy biến áp\n",
    "\n",
    "Chào mừng bạn đến với bài tập thứ hai của khóa học 4. Trong bài tập này, bạn sẽ khám phá cách tóm tắt bằng mô hình máy biến áp. Có, bạn sẽ triển khai bộ giải mã máy biến áp từ đầu, nhưng chúng tôi sẽ hướng dẫn bạn dần dần về nó. Có rất nhiều gợi ý trong cuốn sổ này nên bạn có thể thoải mái sử dụng chúng khi cần thiết. Trên thực tế, đến cuối cuốn sổ này, bạn sẽ triển khai bộ biến áp đầy đủ (cả bộ mã hóa và bộ giải mã) nhưng bạn sẽ chỉ được chấm điểm khi triển khai bộ giải mã vì bộ mã hóa được cung cấp cho bạn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e9709",
   "metadata": {
    "colab_type": "text",
    "id": "4-3lxSnXRWPx"
   },
   "source": [
    "## Mục lục\n",
    "\n",
    "- [Introduction](#0)\n",
    "- [1 - Importing the Dataset](#1)\n",
    "- [2 - Preprocess the Data](#2)\n",
    "- [3 - Positional Encoding](#3)\n",
    "- [4 - Masking](#4)\n",
    "- [5 - Self-attention](#5)\n",
    "- [Exercise 1 - scaled_dot_product_attention](#ex-1)\n",
    "- [6 - Encoder](#6)\n",
    "- [6.1 - Encoder Layer](#6-1)\n",
    "- [6.2 - Full Encoder](#6-2)\n",
    "- [7 - Decoder](#7)\n",
    "- [7.1 - Decoder Layer](#7-1)\n",
    "- [Exercise 2 - DecoderLayer](#ex-2)\n",
    "- [7.2 - Full Decoder](#7-2)\n",
    "- [Exercise 3 - Decoder](#ex-3)\n",
    "- [8 - Transformer](#8)\n",
    "- [Exercise 4 - Transformer](#ex-4)\n",
    "- [9 - Initialize the Model](#9)\n",
    "- [10 - Prepare for Training the Model](#10)\n",
    "- [11 - Summarization](#11)\n",
    "- [Exercise 5 - next_word](#ex-5)\n",
    "- [12 - Train the Model](#12)\n",
    "- [13 - Summarize some sentences!](#13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0da363",
   "metadata": {
    "colab_type": "text",
    "id": "H4NlfEQhRWPy"
   },
   "source": [
    "<a name='0'></a>\n",
    "## Giới thiệu\n",
    "\n",
    "Tóm tắt là một nhiệm vụ quan trọng trong xử lý ngôn ngữ tự nhiên và có thể hữu ích cho doanh nghiệp tiêu dùng. Ví dụ: bot có thể được sử dụng để thu thập các bài viết, tóm tắt chúng và sau đó bạn có thể sử dụng phân tích tâm lý để xác định tâm lý về một số cổ phiếu nhất định. Hôm nay ai lại muốn đọc một bài báo hay một email dài khi bạn có thể xây dựng một máy biến áp để tóm tắt văn bản cho mình? Bắt đầu nào. Khi hoàn thành nhiệm vụ này, bạn sẽ học được:\n",
    "\n",
    "- Sử dụng các chức năng tích hợp để xử lý trước dữ liệu của bạn\n",
    "- Triển khai DotProductAttention\n",
    "- Thực hiện chú ý nhân quả\n",
    "- Hiểu cách thức hoạt động của sự chú ý\n",
    "- Xây dựng mô hình máy biến áp\n",
    "- Đánh giá mô hình của bạn\n",
    "- Tóm tắt một bài viết\n",
    "\n",
    "Như bạn có thể thấy, mô hình này hơi khác so với những mô hình bạn đã triển khai. Điều này chủ yếu dựa vào sự chú ý và không dựa vào trình tự, cho phép tính toán song song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b49d856",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "CChWzW-rEHVb",
    "outputId": "a0b3e98b-7fc6-492d-c8ad-3a263b54f670",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import utils\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "tf.keras.utils.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe093e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import w2_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56fc570",
   "metadata": {
    "colab_type": "text",
    "id": "kEL2rvaHRWP4"
   },
   "source": [
    "<a name='1'></a>\n",
    "##1 - Nhập Dataset\n",
    "Bạn có tập dữ liệu được lưu trong tệp .json mà bạn có thể dễ dàng mở bằng gấu trúc. Chức năng tải đã được xử lý trong `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074bcce3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "Lucas: Hey! How was your day?\r\n",
      "Demi: Hey there! \r\n",
      "Demi: It was pretty fine, actually, thank you!\r\n",
      "Demi: I just got promoted! :D\r\n",
      "Lucas: Whoa! Great news!\r\n",
      "Lucas: Congratulations!\r\n",
      "Lucas: Such a success has to be celebrated.\r\n",
      "Demi: I agree! :D\r\n",
      "Demi: Tonight at Death & Co.?\r\n",
      "Lucas: Sure!\r\n",
      "Lucas: See you there at 10pm?\r\n",
      "Demi: Yeah! See you there! :D\n",
      "\n",
      "Summary:\n",
      "Demi got promoted. She will celebrate that with Lucas at Death & Co at 10 pm.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/corpus\"\n",
    "\n",
    "train_data, test_data = utils.get_train_test_data(data_dir)\n",
    "\n",
    "# Take one example from the dataset and print it\n",
    "example_summary, example_dialogue = train_data.iloc[10]\n",
    "print(f\"Dialogue:\\n{example_dialogue}\")\n",
    "print(f\"\\nSummary:\\n{example_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04210324",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "##2 - Xử lý trước dữ liệu\n",
    "\n",
    "Trước tiên, bạn sẽ thực hiện một số bước tiền xử lý dữ liệu và chia nó thành đầu vào và đầu ra. Tại đây, bạn cũng xóa một số ký tự dành riêng cho tập dữ liệu này và thêm mã thông báo `[EOS]` (end of sentence) vào cuối, giống như đã được thảo luận trong các video bài giảng. Bạn cũng sẽ thêm mã thông báo `[EOS]` (end of sentence) vào đầu câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba397a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "document, summary = utils.preprocess(train_data)\n",
    "document_test, summary_test = utils.preprocess(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe70280",
   "metadata": {},
   "source": [
    "Bây giờ hãy thực hiện quá trình tiền xử lý tiêu chuẩn với thư viện tensorflow. Bạn sẽ cần sửa đổi các bộ lọc vì bạn không muốn xóa mã thông báo `[EOS]`.\n",
    "\n",
    "Sau đó tạo từ vựng bằng cách kết hợp dữ liệu trong tài liệu và phần tóm tắt rồi sử dụng `.fit_on_texts()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dfab3c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 34250\n"
     ]
    }
   ],
   "source": [
    "# The [ and ] from default tokens cannot be removed, because they mark the SOS and EOS token.\n",
    "filters = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n'\n",
    "oov_token = '[UNK]'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token, lower=False)\n",
    "\n",
    "documents_and_summary = pd.concat([document, summary], ignore_index=True)\n",
    "\n",
    "tokenizer.fit_on_texts(documents_and_summary)\n",
    "\n",
    "inputs = tokenizer.texts_to_sequences(document)\n",
    "targets = tokenizer.texts_to_sequences(summary)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(f'Size of vocabulary: {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341b3f5",
   "metadata": {},
   "source": [
    "Bây giờ bạn có thể đệm các chuỗi được mã hóa cho dữ liệu huấn luyện.\n",
    "\n",
    "Vì mục đích của cuốn sổ tay này, bạn cần giới hạn độ dài của các trình tự, vì máy biến áp thực sự là những mô hình lớn và không được đào tạo trong những môi trường nhỏ như vậy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5846dd5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data for being able to run it in this environment.\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "# Pad the sequences.\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b25fb2",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Mã hóa vị trí\n",
    "\n",
    "Theo trình tự các nhiệm vụ, thứ tự tương đối của dữ liệu của bạn là cực kỳ quan trọng đối với ý nghĩa của nó. Khi bạn đào tạo các mạng thần kinh tuần tự như RNN, bạn đã đưa đầu vào của mình vào mạng theo thứ tự. Thông tin về thứ tự dữ liệu của bạn đã được tự động đưa vào mô hình của bạn. Tuy nhiên, khi bạn huấn luyện mạng Transformer bằng cách sử dụng sự chú ý của nhiều đầu, bạn sẽ đưa tất cả dữ liệu của mình vào mô hình cùng một lúc. Mặc dù điều này làm giảm đáng kể thời gian đào tạo nhưng không có thông tin nào về thứ tự dữ liệu của bạn. Đây là nơi mã hóa vị trí hữu ích.\n",
    "\n",
    "Bạn đã học cách triển khai mã hóa vị trí ở một trong các phòng thí nghiệm của tuần này. Tại đây, bạn sẽ sử dụng hàm `positional_encoding` để tạo mã hóa vị trí cho máy biến áp của mình. Chức năng này đã được triển khai cho bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e65672c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d_model):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int): Maximum number of positions to be encoded \n",
    "        d_model (int): Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding (tf.Tensor): A matrix of shape (1, position, d_model) with the positional encodings\n",
    "    \"\"\"\n",
    "    \n",
    "    position = np.arange(positions)[:, np.newaxis]\n",
    "    k = np.arange(d_model)[np.newaxis, :]\n",
    "    i = k // 2\n",
    "    \n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
    "    angle_rads = position * angle_rates\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f1063",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "##4 - Đắp mặt nạ\n",
    "\n",
    "Có hai loại mặt nạ hữu ích khi xây dựng mạng Transformer của bạn: *mặt nạ đệm* và *mặt nạ nhìn về phía trước*. Cả hai đều giúp tính toán softmax đưa ra trọng số thích hợp cho các từ trong câu đầu vào của bạn.\n",
    "\n",
    "Bạn đã học cách triển khai và sử dụng chúng ở một trong các phòng thí nghiệm của tuần này. Ở đây chúng được thực hiện cho bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc7471c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids (matrix like): matrix of size (n, m)\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (n, 1, m)\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding to the attention logits. \n",
    "    # this will allow for broadcasting later when comparing sequences\n",
    "    return seq[:, tf.newaxis, :] \n",
    "\n",
    "\n",
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns a lower triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length (int): matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (sequence_length, sequence_length)\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89110af6",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "##5 - Tự Chú Ý\n",
    "\n",
    "Như tác giả của bài báo về Transformers đã tuyên bố, \"Tất cả những gì bạn cần là sự chú ý\".\n",
    "\n",
    "<img src=\"images/self-attention.png\" alt=\"Encoder\" width=\"600\"/>\n",
    "<caption><center><font color='purple'><b>Hình 1: Trực quan hóa phép tính Tự chú ý</font></center></caption>\n",
    "\n",
    "Việc sử dụng tính năng tự chú ý kết hợp với mạng tích chập truyền thống cho phép thực hiện song song giúp tăng tốc quá trình đào tạo. Bạn sẽ triển khai **chú ý đến sản phẩm chấm theo tỷ lệ** lấy truy vấn, khóa, giá trị và mặt nạ làm đầu vào để trả về các biểu diễn vectơ phong phú, dựa trên sự chú ý của các từ trong chuỗi của bạn. Kiểu tự chú ý này có thể được biểu diễn bằng toán học như sau:\n",
    "$$\n",
    "\\text { Chú ý }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag {4}\\\n",
    "$$\n",
    "\n",
    "* $Q$ là ma trận truy vấn\n",
    "* $K$ là ma trận các khóa\n",
    "* $V$ là ma trận các giá trị\n",
    "* $M$ là mặt nạ tùy chọn bạn chọn để áp dụng\n",
    "* ${d_k}$ là kích thước của các phím, được sử dụng để thu nhỏ mọi thứ để softmax không bị nổ\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Bài tập 1 -scaled_dot_product_attention\n",
    "\n",
    "Triển khai hàm `scaled_dot_product_attention()` để tạo các biểu diễn dựa trên sự chú ý.\n",
    "\n",
    "**Lời nhắc**: Tham số mặt nạ boolean có thể được chuyển vào dưới dạng `none` hoặc dưới dạng đệm hoặc nhìn về phía trước.\n",
    "\n",
    "* Nhân (1. - mặt nạ) với -1e9 trước khi thêm nó vào nhật ký chú ý được chia tỷ lệ.\n",
    "\n",
    "**Gợi ý bổ sung**\n",
    "* Bạn có thể thấy [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul) hữu ích cho phép nhân ma trận (kiểm tra cách bạn có thể sử dụng tham số transpose_b).\n",
    "* Bạn có thể sử dụng [tf.keras.activations.softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) cho softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f434073",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: scaled_dot_product_attention\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead) \n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "    Arguments:\n",
    "        q (tf.Tensor): query of shape (..., seq_len_q, depth)\n",
    "        k (tf.Tensor): key of shape (..., seq_len_k, depth)\n",
    "        v (tf.Tensor): value of shape (..., seq_len_v, depth_v)\n",
    "        mask (tf.Tensor): mask with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- attention_weights\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Multiply q and k transposed.\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk with the square root of dk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:  # Don't replace this None\n",
    "        scaled_attention_logits += (1 - mask) * -1e9\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    # Multiply the attention weights by v\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ed8f5af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " [[[1.   0.62]\n",
      "  [0.62 0.62]\n",
      "  [0.74 0.31]]]\n",
      "\n",
      "Attention weigths:\n",
      " [[[0.   0.38 0.   0.23 0.38]\n",
      "  [0.38 0.   0.   0.23 0.38]\n",
      "  [0.26 0.43 0.   0.16 0.16]]]\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "q = np.array([[1, 1, 0, 1], [0, 1, 1, 1], [1, 0, 1, 1]]).astype(np.float32)\n",
    "k = np.array([[1, 1, 0, 1], [1, 0, 1, 1 ], [1, 1, 1, 0], [0, 0, 0, 1], [0, 1, 0, 1]]).astype(np.float32)\n",
    "v = np.array([[0, 0], [1, 0], [1, 0], [1, 1], [1, 1]]).astype(np.float32)\n",
    "mask = np.array([[[0, 1, 0, 1, 1], [1, 0, 0, 1, 1], [1, 1, 0, 1, 1]]])\n",
    "\n",
    "ou, atw = scaled_dot_product_attention(q, k, v, mask)\n",
    "ou = np.around(ou, decimals=2)\n",
    "atw = np.around(atw, decimals=2)\n",
    "\n",
    "print(f\"Output:\\n {ou}\")\n",
    "print(f\"\\nAttention weigths:\\n {atw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b970a6e",
   "metadata": {},
   "source": [
    "##### __Kết quả mong đợi__\n",
    "\n",
    "```\n",
    "Output:\n",
    " [[[1.   0.62]\n",
    "  [0.62 0.62]\n",
    "  [0.74 0.31]]]\n",
    "\n",
    "Attention weigths:\n",
    " [[[0.   0.38 0.   0.23 0.38]\n",
    "  [0.38 0.   0.   0.23 0.38]\n",
    "  [0.26 0.43 0.   0.16 0.16]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4755bb0b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "w2_unittest.test_scaled_dot_product_attention(scaled_dot_product_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbd521",
   "metadata": {},
   "source": [
    "Công việc tuyệt vời! Bây giờ bạn có thể thực hiện việc tự chú ý. Với điều đó, bạn có thể bắt đầu xây dựng khối mã hóa!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9c92a",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Bộ mã hóa\n",
    "\n",
    "Lớp Bộ mã hóa biến áp kết hợp kiểu xử lý mạng thần kinh tích chập và tự chú ý để cải thiện tốc độ huấn luyện và chuyển ma trận K và V cho Bộ giải mã mà bạn sẽ xây dựng sau trong bài tập. Trong phần bài tập này, bạn sẽ triển khai Bộ mã hóa bằng cách ghép nối sự chú ý nhiều đầu và mạng nơ-ron chuyển tiếp nguồn cấp dữ liệu (Hình 2a).\n",
    "<img src=\"images/encoder_layer.png\" alt=\"Encoder\" width=\"400\"/>\n",
    "<caption><center><font color='purple'><b>Hình 2a: Lớp mã hóa máy biến áp</font></center></caption>\n",
    "\n",
    "* `MultiHeadAttention` bạn có thể coi là tính toán tự chú ý nhiều lần để phát hiện các tính năng khác nhau.\n",
    "* Mạng nơ-ron chuyển tiếp nguồn cấp dữ liệu chứa hai lớp dày đặc mà chúng tôi sẽ triển khai dưới dạng chức năng `FullyConnected`\n",
    "\n",
    "Trước tiên, câu đầu vào của bạn sẽ đi qua *lớp chú ý nhiều đầu*, trong đó bộ mã hóa xem xét các từ khác trong câu đầu vào khi mã hóa một từ cụ thể. Sau đó, đầu ra của lớp chú ý nhiều đầu được đưa đến *mạng thần kinh chuyển tiếp nguồn cấp dữ liệu*. Mạng chuyển tiếp nguồn cấp dữ liệu giống hệt nhau được áp dụng độc lập cho từng vị trí.\n",
    "\n",
    "* Đối với lớp `MultiHeadAttention`, bạn sẽ sử dụng [MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) được triển khai trong Keras. Nếu bạn tò mò về cách chia ma trận truy vấn Q, ma trận khóa K và ma trận giá trị V thành các phần đầu khác nhau, bạn có thể xem qua phần triển khai.\n",
    "* Bạn cũng sẽ sử dụng [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) với hai lớp dày đặc để xây dựng các lớp mạng thần kinh chuyển tiếp nguồn cấp dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3fd59d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    \"\"\"\n",
    "    Returns a sequential model consisting of two dense layers. The first dense layer has\n",
    "    fully_connected_dim neurons and is activated by relu. The second dense layer has\n",
    "    embedding_dim and no activation.\n",
    "\n",
    "    Arguments:\n",
    "        embedding_dim (int): output dimension\n",
    "        fully_connected_dim (int): dimension of the hidden layer\n",
    "\n",
    "    Returns:\n",
    "        _ (tf.keras.Model): sequential model\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, d_model)\n",
    "        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7003a",
   "metadata": {},
   "source": [
    "<a name='6-1'></a>\n",
    "### 6.1 Lớp mã hóa\n",
    "\n",
    "Giờ đây, bạn có thể ghép nối sự chú ý của nhiều đầu và chuyển tiếp mạng nơ-ron với nhau trong một lớp mã hóa! Bạn cũng sẽ sử dụng các kết nối còn lại và chuẩn hóa lớp để giúp tăng tốc độ đào tạo (Hình 2a).\n",
    "\n",
    "Khối bộ mã hóa (Hình 2) đã được triển khai cho bạn. Hãy xem xét kỹ cách triển khai nó, vì sau này bạn sẽ phải tự tạo bộ giải mã và rất nhiều mã rất giống nhau. Khối mã hóa thực hiện các bước sau:\n",
    "1. Nó đưa các ma trận Q, V, K và mặt nạ boolean vào lớp chú ý nhiều đầu. Hãy nhớ rằng để tính toán *tự*-chú ý Q, V và K đều giống nhau. Bạn cũng sẽ thực hiện Dropout trong lớp chú ý nhiều đầu này trong quá trình đào tạo.\n",
    "2. Có một kết nối bỏ qua để thêm đầu vào `x` ban đầu của bạn và đầu ra của lớp chú ý nhiều đầu.\n",
    "3. Sau khi thêm kết nối bỏ qua, đầu ra sẽ đi qua lớp chuẩn hóa đầu tiên.\n",
    "4. Cuối cùng, các bước 1-3 được lặp lại nhưng với mạng nơ-ron chuyển tiếp nguồn cấp dữ liệu có lớp bỏ học thay vì lớp chú ý nhiều đầu.\n",
    "\n",
    "<chi tiết>\n",
    "<summary><font size=\"2\" color=\"darkgreen\"><b>Thông tin bổ sung (Nhấp để mở rộng)</b></font></summary>\n",
    "\n",
    "* Phương thức `__init__` tạo tất cả các lớp sẽ được truy cập bằng phương thức `call`. Bất cứ nơi nào bạn muốn sử dụng một lớp được xác định bên trong phương thức `__init__`, bạn sẽ phải sử dụng cú pháp `self.[insert layer name]`.\n",
    "* Bạn sẽ thấy tài liệu về [MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) hữu ích. *Lưu ý rằng nếu truy vấn, khóa và giá trị giống nhau thì hàm này sẽ thực hiện tự chú ý.*\n",
    "* Các đối số lệnh gọi cho `self.mha` là (Trong đó B dành cho batch_size, T dành cho hình dạng chuỗi mục tiêu và S là out_shape):\n",
    "- `query`: Tensor truy vấn có hình dạng (B, T, dim).\n",
    "- `value`: Giá trị Tensor của hình dạng (B, S, dim).\n",
    "- `key`: Phím tùy chọn Tensor hình dạng (B, S, dim). Nếu không được cung cấp, sẽ sử dụng cùng một giá trị cho cả khóa và giá trị, đây là trường hợp phổ biến nhất.\n",
    "- `attention_mask`: một mặt nạ boolean có hình dạng (B, T, S), ngăn sự chú ý đến các vị trí nhất định. Mặt nạ boolean chỉ định thành phần truy vấn nào có thể tham gia vào thành phần chính nào, 1 biểu thị sự chú ý và 0 biểu thị không chú ý. Việc phát sóng có thể xảy ra đối với các kích thước lô bị thiếu và kích thước phần đầu.\n",
    "- `return_attention_scores`: Một boolean để cho biết liệu đầu ra có phải là đầu ra chú ý nếu Đúng hay (attention_output, chú ý_scores) nếu Sai. Mặc định là Sai.\n",
    "- `training`: Python boolean cho biết lớp sẽ hoạt động ở chế độ huấn luyện (thêm bỏ học) hay ở chế độ suy luận (không bỏ học). Mặc định là sử dụng chế độ đào tạo của lớp/mô hình cha hoặc Sai (suy luận) nếu không có lớp cha. Hãy xem [tf.keras.layers.Dropout](https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/Dropout) để biết thêm chi tiết (Đọc thêm trong [tf.keras.layers.Dropout](https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/Dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c1452b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This architecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out (tf.Tensor): Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        # calculate self-attention using mha(~1 line).\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        self_mha_output = self.mha(x, x, x, mask)  # Self attention (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # skip connection\n",
    "        # apply layer normalization on sum of the input and the attention output to get the  \n",
    "        # output of the multi-head attention layer\n",
    "        skip_x_attention = self.layernorm1(x + self_mha_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # pass the output of the multi-head attention layer through a ffn\n",
    "        ffn_output = self.ffn(skip_x_attention)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply dropout layer to ffn output during training\n",
    "        # use `training=training`\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization on sum of the output from multi-head attention (skip connection) and ffn output\n",
    "        # to get the output of the encoder layer\n",
    "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        \n",
    "        return encoder_layer_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36f13b",
   "metadata": {},
   "source": [
    "<a name='6-2'></a>\n",
    "### 6.2 - Bộ mã hóa đầy đủ\n",
    "\n",
    "Bây giờ bạn đã sẵn sàng xây dựng Bộ mã hóa biến áp đầy đủ (Hình 2b), nơi bạn sẽ nhúng đầu vào của mình và thêm các mã hóa vị trí mà bạn đã tính toán. Sau đó, bạn sẽ cung cấp các phần nhúng được mã hóa của mình vào một chồng các lớp Bộ mã hóa.\n",
    "\n",
    "<img src=\"images/encoder.png\" alt=\"Encoder\" width=\"330\"/>\n",
    "<caption><center><font color='purple'><b>Hình 2b: Bộ mã hóa máy biến áp</font></center></caption>\n",
    "\n",
    "Lớp Bộ mã hóa được triển khai cho bạn. Nó thực hiện các bước sau:\n",
    "1. Truyền đầu vào qua lớp Nhúng.\n",
    "2. Chia tỷ lệ phần nhúng bằng cách nhân nó với căn bậc hai của kích thước phần nhúng.\n",
    "3. Thêm mã hóa vị trí: self.pos_encoding `[:, :seq_len, :]` vào phần nhúng.\n",
    "4. Truyền phần nhúng được mã hóa qua lớp bỏ học\n",
    "5. Truyền đầu ra của lớp bỏ học qua ngăn xếp các lớp mã hóa bằng vòng lặp for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d677d14e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "        \n",
    "    \"\"\"  \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.embedding_dim)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Pass input through the Embedding layer\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        # Scale embedding by multiplying it by the square root of the embedding dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        # Add the position encoding to embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        # Pass the encoded embedding through a dropout layer\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x, training=training)\n",
    "        # Pass the output through the stack of encoding layers \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7356fd",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "##7 - Bộ giải mã\n",
    "\n",
    "Bây giờ là lúc triển khai bộ giải mã. Bạn đã thấy nó trong video và bạn có thể sử dụng một số trợ giúp bằng cách xem cách triển khai bộ mã hóa ở trên. Lớp Bộ giải mã lấy ma trận K và V do Bộ mã hóa tạo ra và tính toán lớp chú ý nhiều đầu thứ hai với ma trận Q từ đầu ra (Hình 3a).\n",
    "\n",
    "<img src=\"images/decoder_layer.png\" alt=\"Decoder\" width=\"250\"/>\n",
    "<caption><center><font color='purple'><b>Hình 3a: Lớp Transformer Decoding</font></center></caption>\n",
    "\n",
    "<a name='7-1'></a>\n",
    "### 7.1 - Lớp giải mã\n",
    "Một lần nữa, bạn sẽ ghép nối sự chú ý nhiều đầu với mạng nơ-ron chuyển tiếp nguồn cấp dữ liệu, nhưng lần này bạn sẽ triển khai hai lớp chú ý nhiều đầu. Bạn cũng sẽ sử dụng các kết nối còn lại và chuẩn hóa lớp để giúp tăng tốc độ đào tạo (Hình 3a).\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Bài tập 2 - DecodeLayer\n",
    "\n",
    "Triển khai `DecodeLayer()` bằng phương thức `call()`\n",
    "\n",
    "1. Khối 1 là lớp chú ý nhiều đầu với kết nối còn lại và mặt nạ nhìn về phía trước. Giống như trong `EncodeLayer`, Dropout được xác định trong lớp chú ý nhiều đầu.\n",
    "2. Khối 2 sẽ tính đến đầu ra của Bộ mã hóa, do đó lớp chú ý nhiều đầu sẽ nhận K và V từ bộ mã hóa và Q từ Khối 1. Sau đó, bạn sẽ áp dụng lớp chuẩn hóa và kết nối dư, chỉ cần giống như bạn đã làm trước đây với `EncodeLayer`.\n",
    "3. Cuối cùng, Khối 3 là mạng nơ-ron chuyển tiếp nguồn cấp dữ liệu với các lớp loại bỏ và chuẩn hóa cũng như kết nối còn lại.\n",
    "\n",
    "**Gợi ý bổ sung:**\n",
    "* Hai khối đầu tiên khá giống với EncodingLayer ngoại trừ bạn sẽ trả về `attention_scores` khi tính toán self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8d3a38d",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # First dense layer\n",
    "            tf.keras.layers.Dense(embedding_dim)  # Second dense layer\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # Block 1: Self-attention\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, attention_mask=look_ahead_mask, return_attention_scores=True, training=training)\n",
    "        out1 = self.layernorm1(x + attn1)  # Apply residual connection followed by layer normalization\n",
    "        \n",
    "        # Block 2: Attention over encoder output\n",
    "        attn2, attn_weights_block2 = self.mha2(out1, enc_output, enc_output, attention_mask=padding_mask, return_attention_scores=True, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2)  # Apply residual connection followed by layer normalization\n",
    "        \n",
    "        # Block 3: Fully connected feed-forward network\n",
    "        ffn_output = self.ffn(out2)  # Pass through feed forward network\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)  # Apply dropout\n",
    "        out3 = self.layernorm3(out2 + ffn_output)  # Apply residual connection followed by layer normalization\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41686c8b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding_dim=12 and num_heads=16:\n",
      "\n",
      "q has shape:(1, 15, 12)\n",
      "Output of encoder has shape:(1, 7, 8)\n",
      "\n",
      "Output of decoder layer has shape:(1, 15, 12)\n",
      "Att Weights Block 1 has shape:(1, 16, 15, 15)\n",
      "Att Weights Block 2 has shape:(1, 16, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "key_dim = 12\n",
    "n_heads = 16\n",
    "\n",
    "decoderLayer_test = DecoderLayer(embedding_dim=key_dim, num_heads=n_heads, fully_connected_dim=32)\n",
    "\n",
    "q = np.ones((1, 15, key_dim))\n",
    "encoder_test_output = tf.convert_to_tensor(np.random.rand(1, 7, 8))\n",
    "look_ahead_mask = create_look_ahead_mask(q.shape[1])\n",
    "\n",
    "out, attn_w_b1, attn_w_b2 = decoderLayer_test(q, encoder_test_output, False, look_ahead_mask, None)\n",
    "\n",
    "print(f\"Using embedding_dim={key_dim} and num_heads={n_heads}:\\n\")\n",
    "print(f\"q has shape:{q.shape}\")\n",
    "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
    "\n",
    "print(f\"Output of decoder layer has shape:{out.shape}\")\n",
    "print(f\"Att Weights Block 1 has shape:{attn_w_b1.shape}\")\n",
    "print(f\"Att Weights Block 2 has shape:{attn_w_b2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b85a3",
   "metadata": {},
   "source": [
    "##### __Kết quả mong đợi__\n",
    "\n",
    "```\n",
    "Output:\n",
    "Using embedding_dim=12 and num_heads=16:\n",
    "\n",
    "q has shape:(1, 15, 12)\n",
    "Output of encoder has shape:(1, 7, 8)\n",
    "\n",
    "Output of decoder layer has shape:(1, 15, 12)\n",
    "Att Weights Block 1 has shape:(1, 16, 15, 15)\n",
    "Att Weights Block 2 has shape:(1, 16, 15, 7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "932f7320",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "w2_unittest.test_decoderlayer(DecoderLayer, create_look_ahead_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b82ccf",
   "metadata": {},
   "source": [
    "<a name='7-2'></a>\n",
    "### 7.2 - Bộ giải mã đầy đủ\n",
    "Bạn đã gần tới! Đã đến lúc sử dụng lớp Bộ giải mã của bạn để xây dựng Bộ giải mã Biến áp đầy đủ (Hình 3b). Bạn sẽ nhúng đầu ra của mình và thêm mã hóa vị trí. Sau đó, bạn sẽ cung cấp các phần nhúng được mã hóa của mình vào một chồng các lớp Bộ giải mã.\n",
    "\n",
    "\n",
    "<img src=\"images/decoder.png\" alt=\"Decoder\" width=\"300\"/>\n",
    "<caption><center><font color='purple'><b>Hình 3b: Bộ giải mã máy biến áp</font></center></caption>\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Bài tập 3 – Bộ giải mã\n",
    "\n",
    "Triển khai `Bộ giải mã()` bằng cách sử dụng phương thức `call()` để nhúng đầu ra của bạn, thêm mã hóa vị trí và triển khai nhiều lớp bộ giải mã.\n",
    "\n",
    "Trong bài tập này, bạn sẽ khởi tạo Bộ giải mã của mình bằng lớp Nhúng, mã hóa vị trí và nhiều Lớp giải mã. Phương thức `call()` của bạn sẽ thực hiện các bước sau:\n",
    "1. Chuyển đầu ra đã tạo của bạn qua lớp Nhúng.\n",
    "2. Chia tỷ lệ nhúng của bạn bằng cách nhân nó với căn bậc hai của kích thước nhúng của bạn. Hãy nhớ truyền thứ nguyên nhúng vào kiểu dữ liệu `tf.float32` trước khi tính căn bậc hai.\n",
    "3. Thêm mã hóa vị trí: self.pos_encoding `[:, :seq_len, :]` vào phần nhúng của bạn.\n",
    "4. Truyền phần nhúng được mã hóa qua lớp bỏ học, nhớ sử dụng tham số `đào tạo` để đặt chế độ đào tạo mô hình.\n",
    "5. Truyền đầu ra của lớp bỏ học qua ngăn xếp các lớp Giải mã bằng vòng lặp for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57dde3be",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "                 maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        # Create word embeddings\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Scale embeddings by multiplying by the square root of their dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        \n",
    "        # Add positional encodings to word embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # Apply a dropout layer to x\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # Use a for loop to pass x through a stack of decoder layers and update attention_weights\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights[f'decoder_layer{i+1}_block1_self_att'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2_decenc_att'] = block2\n",
    "        \n",
    "        # x.shape == (batch_size, target_seq_len, fully_connected_dim)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04e877fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_layers=5, embedding_dim=13 and num_heads=17:\n",
      "\n",
      "x has shape:(3, 4)\n",
      "Output of encoder has shape:(3, 7, 9)\n",
      "\n",
      "Output of decoder has shape:(3, 4, 13)\n",
      "\n",
      "Attention weights:\n",
      "decoder_layer1_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer1_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer2_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer2_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer3_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer3_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer4_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer4_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer5_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer5_block2_decenc_att has shape:(3, 17, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "n_layers = 5\n",
    "emb_d = 13\n",
    "n_heads = 17\n",
    "fully_connected_dim = 16\n",
    "target_vocab_size = 300\n",
    "maximum_position_encoding = 6\n",
    "\n",
    "x = np.array([[3, 2, 1, 1], [2, 1, 1, 0], [2, 1, 1, 0]])\n",
    "\n",
    "encoder_test_output = tf.convert_to_tensor(np.random.rand(3, 7, 9))\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
    "\n",
    "decoder_test = Decoder(n_layers, emb_d, n_heads, fully_connected_dim, target_vocab_size,maximum_position_encoding)\n",
    "                   \n",
    "outd, att_weights = decoder_test(x, encoder_test_output, False, look_ahead_mask, None)\n",
    "\n",
    "print(f\"Using num_layers={n_layers}, embedding_dim={emb_d} and num_heads={n_heads}:\\n\")\n",
    "print(f\"x has shape:{x.shape}\")\n",
    "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
    "\n",
    "print(f\"Output of decoder has shape:{outd.shape}\\n\")\n",
    "print(\"Attention weights:\")\n",
    "for name, tensor in att_weights.items():\n",
    "    print(f\"{name} has shape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2ff15",
   "metadata": {},
   "source": [
    "##### __Kết quả mong đợi__\n",
    "\n",
    "```\n",
    "Using num_layers=5, embedding_dim=13 and num_heads=17:\n",
    "\n",
    "x has shape:(3, 4)\n",
    "Output of encoder has shape:(3, 7, 9)\n",
    "\n",
    "Output of decoder has shape:(3, 4, 13)\n",
    "\n",
    "Attention weights:\n",
    "decoder_layer1_block1_self_att has shape:(3, 17, 4, 4)\n",
    "decoder_layer1_block2_decenc_att has shape:(3, 17, 4, 7)\n",
    "decoder_layer2_block1_self_att has shape:(3, 17, 4, 4)\n",
    "decoder_layer2_block2_decenc_att has shape:(3, 17, 4, 7)\n",
    "decoder_layer3_block1_self_att has shape:(3, 17, 4, 4)\n",
    "decoder_layer3_block2_decenc_att has shape:(3, 17, 4, 7)\n",
    "decoder_layer4_block1_self_att has shape:(3, 17, 4, 4)\n",
    "decoder_layer4_block2_decenc_att has shape:(3, 17, 4, 7)\n",
    "decoder_layer5_block1_self_att has shape:(3, 17, 4, 4)\n",
    "decoder_layer5_block2_decenc_att has shape:(3, 17, 4, 7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e92745de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "w2_unittest.test_decoder(Decoder, create_look_ahead_mask, create_padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ba4b5",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "##8 - Máy biến áp\n",
    "\n",
    "Phù! Đây quả là một nhiệm vụ tuyệt vời! Chúc mừng! Bạn đã hoàn thành tất cả công việc khó khăn, bây giờ là lúc để tập hợp tất cả lại với nhau.\n",
    "\n",
    "<img src=\"images/transformer.png\" alt=\"Transformer\" width=\"550\"/>\n",
    "<caption><center><font color='purple'><b>Hình 4: Máy biến áp</font></center></caption>\n",
    "\n",
    "Luồng dữ liệu thông qua Kiến trúc Transformer như sau:\n",
    "* Đầu tiên, đầu vào của bạn đi qua Bộ mã hóa, đây chỉ là các lớp Bộ mã hóa lặp lại mà bạn đã triển khai:\n",
    "- nhúng và mã hóa vị trí đầu vào của bạn\n",
    "- sự chú ý nhiều đầu vào đầu vào của bạn\n",
    "- mạng lưới thần kinh chuyển tiếp để giúp phát hiện các tính năng\n",
    "* Sau đó, đầu ra được dự đoán sẽ đi qua Bộ giải mã, bao gồm các lớp giải mã mà bạn đã triển khai:\n",
    "- nhúng và mã hóa vị trí của đầu ra\n",
    "- sự chú ý của nhiều người vào đầu ra được tạo của bạn\n",
    "- chú ý nhiều đầu với Q từ lớp chú ý nhiều đầu đầu tiên và K và V từ Bộ mã hóa\n",
    "- mạng lưới thần kinh chuyển tiếp nguồn cấp dữ liệu để giúp phát hiện các tính năng\n",
    "* Cuối cùng, sau lớp Bộ giải mã thứ N, một lớp dày đặc và một softmax được áp dụng để tạo dự đoán cho đầu ra tiếp theo trong chuỗi của bạn.\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Bài tập 4 – Máy biến áp\n",
    "\n",
    "Triển khai `Transformer()` bằng phương thức `call()`\n",
    "1. Chuyển đầu vào qua Bộ mã hóa với mặt nạ thích hợp.\n",
    "2. Truyền đầu ra bộ mã hóa và mục tiêu qua Bộ giải mã với mặt nạ thích hợp.\n",
    "3. Áp dụng phép biến đổi tuyến tính và softmax để có được dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9e6cb07",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, \n",
    "               target_vocab_size, max_positional_encoding_input,\n",
    "               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               input_vocab_size=input_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_input,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size, \n",
    "                               maximum_position_encoding=max_positional_encoding_target,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self, input_sentence, output_sentence, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the entire Transformer\n",
    "        Arguments:\n",
    "            input_sentence (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the input sentence\n",
    "            output_sentence (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the output sentence\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            enc_padding_mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            dec_padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            final_output (tf.Tensor): The final output of the model\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights for the decoder\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        ### START CODE HERE ###\n",
    "        # call self.encoder with the appropriate arguments to get the encoder output\n",
    "        enc_output = self.encoder(input_sentence, training, enc_padding_mask)\n",
    "        \n",
    "        # call self.decoder with the appropriate arguments to get the decoder output\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)\n",
    "        dec_output, attention_weights = self.decoder(output_sentence, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # pass decoder output through a linear layer and softmax (~1 line)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cd93c99",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_layers=3, target_vocab_size=350 and num_heads=17:\n",
      "\n",
      "sentence_a has shape:(1, 7)\n",
      "sentence_b has shape:(1, 7)\n",
      "\n",
      "Output of transformer (summary) has shape:(1, 7, 350)\n",
      "\n",
      "Attention weights:\n",
      "decoder_layer1_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer1_block2_decenc_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer2_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer2_block2_decenc_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer3_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer3_block2_decenc_att has shape:(1, 17, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "n_layers = 3\n",
    "emb_d = 13\n",
    "n_heads = 17\n",
    "fully_connected_dim = 8\n",
    "input_vocab_size = 300\n",
    "target_vocab_size = 350\n",
    "max_positional_encoding_input = 12\n",
    "max_positional_encoding_target = 12\n",
    "\n",
    "transformer = Transformer(n_layers, \n",
    "    emb_d, \n",
    "    n_heads, \n",
    "    fully_connected_dim, \n",
    "    input_vocab_size, \n",
    "    target_vocab_size, \n",
    "    max_positional_encoding_input,\n",
    "    max_positional_encoding_target)\n",
    "\n",
    "# 0 is the padding value\n",
    "sentence_a = np.array([[2, 3, 1, 3, 0, 0, 0]])\n",
    "sentence_b = np.array([[1, 3, 4, 0, 0, 0, 0]])\n",
    "\n",
    "enc_padding_mask = create_padding_mask(sentence_a)\n",
    "dec_padding_mask = create_padding_mask(sentence_a)\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(sentence_a.shape[1])\n",
    "\n",
    "test_summary, att_weights = transformer(\n",
    "    sentence_a,\n",
    "    sentence_b,\n",
    "    False,\n",
    "    enc_padding_mask,\n",
    "    look_ahead_mask,\n",
    "    dec_padding_mask\n",
    ")\n",
    "\n",
    "print(f\"Using num_layers={n_layers}, target_vocab_size={target_vocab_size} and num_heads={n_heads}:\\n\")\n",
    "print(f\"sentence_a has shape:{sentence_a.shape}\")\n",
    "print(f\"sentence_b has shape:{sentence_b.shape}\")\n",
    "\n",
    "print(f\"\\nOutput of transformer (summary) has shape:{test_summary.shape}\\n\")\n",
    "print(\"Attention weights:\")\n",
    "for name, tensor in att_weights.items():\n",
    "    print(f\"{name} has shape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9f812",
   "metadata": {},
   "source": [
    "##### __Kết quả mong đợi__\n",
    "\n",
    "```\n",
    "Using num_layers=3, target_vocab_size=350 and num_heads=17:\n",
    "\n",
    "sentence_a has shape:(1, 7)\n",
    "sentence_b has shape:(1, 7)\n",
    "\n",
    "Output of transformer (summary) has shape:(1, 7, 350)\n",
    "\n",
    "Attention weights:\n",
    "decoder_layer1_block1_self_att has shape:(1, 17, 7, 7)\n",
    "decoder_layer1_block2_decenc_att has shape:(1, 17, 7, 7)\n",
    "decoder_layer2_block1_self_att has shape:(1, 17, 7, 7)\n",
    "decoder_layer2_block2_decenc_att has shape:(1, 17, 7, 7)\n",
    "decoder_layer3_block1_self_att has shape:(1, 17, 7, 7)\n",
    "decoder_layer3_block2_decenc_att has shape:(1, 17, 7, 7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2d035a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "w2_unittest.test_transformer(Transformer, create_look_ahead_mask, create_padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8a0c2",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "##9 - Khởi tạo Model\n",
    "Bây giờ bạn đã xác định được mô hình, bạn có thể khởi tạo và huấn luyện nó. Đầu tiên bạn có thể khởi tạo mô hình với các thông số bên dưới. Lưu ý rằng nhìn chung những mô hình này lớn hơn nhiều và bạn đang sử dụng phiên bản nhỏ hơn để phù hợp với môi trường này và có thể huấn luyện nó chỉ trong vài phút.\n",
    "\n",
    "Mô hình cơ sở được mô tả trong bài viết gốc về Transformer đã sử dụng `num_layers=6`, `embedding_dim=512` và `full_connected_dim=2048`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5f79f64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers = 2\n",
    "embedding_dim = 128\n",
    "fully_connected_dim = 128\n",
    "num_heads = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "# Initialize the model\n",
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    embedding_dim, \n",
    "    num_heads, \n",
    "    fully_connected_dim,\n",
    "    vocab_size, \n",
    "    vocab_size, \n",
    "    positional_encoding_length, \n",
    "    positional_encoding_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71473c27",
   "metadata": {},
   "source": [
    "<a name='10'></a>\n",
    "##10 - Chuẩn bị đào tạo người mẫu\n",
    "\n",
    "Bài viết biến áp ban đầu sử dụng trình tối ưu hóa Adam với việc lập kế hoạch tốc độ học tập tùy chỉnh mà chúng tôi xác định trong ô bên dưới. Điều này đã được chứng minh bằng thực nghiệm để tạo ra sự hội tụ nhanh hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb402089",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(embedding_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad854ab6",
   "metadata": {},
   "source": [
    "Dưới đây bạn có thể vẽ biểu đồ về tốc độ học tập tùy chỉnh trông như thế nào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35a17a59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfba386",
   "metadata": {},
   "source": [
    "Tiếp theo, bạn thiết lập phần lỗ. Vì các chuỗi mục tiêu được đệm nên điều quan trọng là phải áp dụng mặt nạ đệm khi tính toán tổn thất.\n",
    "\n",
    "Bạn sẽ sử dụng hàm mất entropy chéo phân loại thưa thớt (`tf.keras.losses.SparseCategoricalCrossentropy`) và đặt tham số `from_logits` thành Sai vì Transformer không xuất ra nhật ký thô vì lớp cuối cùng có kích hoạt softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99fc8885",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def masked_loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# Here you will store the losses, so you can later plot them\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db3f0b",
   "metadata": {},
   "source": [
    "Bây giờ bạn có thể xác định chức năng đào tạo tùy chỉnh của mình. Nếu bạn không rành về tensorflow, bạn có thể hiểu hàm này như một giải pháp thay thế cho việc sử dụng `model.compile()` và `model.fit()`, nhưng có thêm tính linh hoạt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79092091",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, inp, tar):\n",
    "    \"\"\"\n",
    "    One training step for the transformer\n",
    "    Arguments:\n",
    "        inp (tf.Tensor): Input data to summarize\n",
    "        tar (tf.Tensor): Target (summary)\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "    dec_padding_mask = create_padding_mask(inp) # Notice that both encoder and decoder padding masks are equal\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = model(\n",
    "            inp,\n",
    "            tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            look_ahead_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = masked_loss(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480d5fd",
   "metadata": {},
   "source": [
    "Bây giờ bạn đã sẵn sàng để đào tạo mô hình. Nhưng trước khi bắt đầu đào tạo, bạn cũng có thể xác định thêm một bộ hàm để thực hiện suy luận. Vì bạn đang sử dụng vòng lặp đào tạo tùy chỉnh nên bạn có thể làm bất cứ điều gì bạn muốn giữa các bước đào tạo. Và chẳng phải sẽ rất thú vị khi xem sau mỗi kỷ nguyên một số ví dụ về cách hoạt động của mô hình sao?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e05c54",
   "metadata": {},
   "source": [
    "<a name='11'></a>\n",
    "##11 - Tóm tắt\n",
    "\n",
    "Điều cuối cùng bạn sẽ thực hiện là suy luận. Với điều này, bạn sẽ có thể tạo ra các bản tóm tắt thực tế của các tài liệu. Bạn sẽ sử dụng một phương pháp đơn giản gọi là giải mã tham lam, có nghĩa là bạn sẽ dự đoán từng từ một và thêm nó vào đầu ra. Bạn sẽ bắt đầu với mã thông báo `[SOS]` và lặp lại suy luận từng từ cho đến khi mô hình trả về cho bạn mã thông báo `[EOS]` hoặc cho đến khi bạn đạt đến độ dài tối đa của câu (bạn cần thêm giới hạn này, nếu không thì mô hình được đào tạo kém có thể cung cấp cho bạn vô số câu mà không bao giờ tạo ra mã thông báo `[EOS]`.\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Bài tập 5 - next_word\n",
    "Viết hàm trợ giúp dự đoán từ tiếp theo để bạn có thể dùng nó để viết cả câu. Gợi ý: điều này rất giống với những gì xảy ra trong train_step, nhưng bạn phải đặt quá trình huấn luyện mô hình thành Sai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "175fae70",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: next_word\n",
    "def next_word(model, encoder_input, output):\n",
    "    \"\"\"\n",
    "    Helper function for summarization that uses the model to predict just the next word.\n",
    "    Arguments:\n",
    "        encoder_input (tf.Tensor): Input data to summarize\n",
    "        output (tf.Tensor): (incomplete) target (summary)\n",
    "    Returns:\n",
    "        predicted_id (tf.Tensor): The id of the predicted word\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    # Create a padding mask for the input (encoder)\n",
    "    enc_padding_mask = create_padding_mask(encoder_input)\n",
    "    # Create a look-ahead mask for the output\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
    "    # Create a padding mask for the input (decoder)\n",
    "    dec_padding_mask = create_padding_mask(encoder_input)\n",
    "\n",
    "    # Run the prediction of the next word with the transformer model\n",
    "    predictions, attention_weights = model(\n",
    "        encoder_input,\n",
    "        output,\n",
    "        False,\n",
    "        enc_padding_mask,\n",
    "        look_ahead_mask,\n",
    "        dec_padding_mask\n",
    "    )\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    predictions = predictions[: ,-1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    return predicted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af50d0",
   "metadata": {},
   "source": [
    "Kiểm tra xem chức năng của bạn có hoạt động không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e97ba77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token: [[14859]]\n",
      "Predicted word: masses\n"
     ]
    }
   ],
   "source": [
    "# Take a random sentence as an input\n",
    "input_document = tokenizer.texts_to_sequences([\"a random sentence\"])\n",
    "input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "# Take the start of sentence token as the only token in the output to predict the next word\n",
    "output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
    "\n",
    "# predict the next word with your function\n",
    "predicted_token = next_word(transformer, encoder_input, output)\n",
    "print(f\"Predicted token: {predicted_token}\")\n",
    "\n",
    "predicted_word = tokenizer.sequences_to_texts(predicted_token.numpy())[0]\n",
    "print(f\"Predicted word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157031c",
   "metadata": {},
   "source": [
    "##### __Kết quả mong đợi__\n",
    "\n",
    "```\n",
    "Predicted token: [[14859]]\n",
    "Predicted word: masses\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bd98959",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "w2_unittest.test_next_word(next_word, transformer, encoder_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6177dc6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def summarize(model, input_document):\n",
    "    \"\"\"\n",
    "    A function for summarization using the transformer model\n",
    "    Arguments:\n",
    "        input_document (tf.Tensor): Input data to summarize\n",
    "    Returns:\n",
    "        _ (str): The summary of the input_document\n",
    "    \"\"\"    \n",
    "    input_document = tokenizer.texts_to_sequences([input_document])\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "    \n",
    "    output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        predicted_id = next_word(model, encoder_input, output)\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        \n",
    "        if predicted_id == tokenizer.word_index[\"[EOS]\"]:\n",
    "            break\n",
    "\n",
    "    return tokenizer.sequences_to_texts(output.numpy())[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b15117",
   "metadata": {},
   "source": [
    "Bây giờ bạn đã có thể tóm tắt một câu! Nhưng hãy cẩn thận, vì mô hình chưa được đào tạo nên nó sẽ chỉ tạo ra những kết quả vô nghĩa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bae4d5f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set example:\n",
      "[SOS] amanda: i baked  cookies. do you want some?  jerry: sure!  amanda: i'll bring you tomorrow :-) [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
      "\n",
      "Model written summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[SOS] masses kindergarten concept kindergarten concept bloomer wilingness sux sam kindergarten lisabeth kindergarten sawyer's sawyer's masses concept bloomer lisabeth bloomer wilingness 80000 bt hotsummer hoax hoax kieslowski wilingness 80000 dont't elis' 🐶❤️👍 cots saaaad evelynn inexperienced suji zubac forthcoming callum farmers extraordinary callum kindergarten worthy extraordinary readable 🐶❤️👍 thinkgn 🐶❤️👍 cots\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_example = 0\n",
    "\n",
    "# Check a summary of a document from the training set\n",
    "print('Training set example:')\n",
    "print(document[training_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary[training_set_example])\n",
    "print('\\nModel written summary:')\n",
    "summarize(transformer, document[training_set_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6f836",
   "metadata": {},
   "source": [
    "<a name='12'></a>\n",
    "#12 - Huấn luyện người mẫu\n",
    "\n",
    "Bây giờ cuối cùng bạn có thể huấn luyện mô hình. Dưới đây là một vòng lặp sẽ huấn luyện mô hình của bạn trong 20 kỷ nguyên. lưu ý rằng sẽ mất khoảng 30 giây mỗi kỷ nguyên (ngoại trừ một số kỷ nguyên đầu tiên có thể mất vài phút mỗi kỷ nguyên).\n",
    "\n",
    "Lưu ý rằng sau mỗi giai đoạn, bạn thực hiện tóm tắt một trong các câu trong bộ kiểm tra và in nó ra để bạn có thể thấy mô hình của mình đang được cải thiện như thế nào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2bf5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take an example from the test set, to monitor it during training\n",
    "test_example = 0\n",
    "true_summary = summary_test[test_example]\n",
    "true_document = document_test[test_example]\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    number_of_batches=len(list(enumerate(dataset)))\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        print(f'Epoch {epoch+1}, Batch {batch+1}/{number_of_batches}', end='\\r')\n",
    "        train_step(transformer, inp, tar)\n",
    "    \n",
    "    print (f'Epoch {epoch+1}, Loss {train_loss.result():.4f}')\n",
    "    losses.append(train_loss.result())\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "    print('Example summarization on the test set:')\n",
    "    print('  True summarization:')\n",
    "    print(f'    {true_summary}')\n",
    "    print('  Predicted summarization:')\n",
    "    print(f'    {summarize(transformer, true_document)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35687ddc",
   "metadata": {},
   "source": [
    "Vẽ hàm mất mát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d5335",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a53f16",
   "metadata": {},
   "source": [
    "<a name='13'></a>\n",
    "#13 – Tóm tắt một số câu!\n",
    "\n",
    "Dưới đây bạn có thể xem ví dụ về tóm tắt một câu từ tập huấn luyện và một câu từ tập kiểm tra. Hãy xem bạn có nhận thấy điều gì thú vị ở họ không nhé!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493b755",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "training_set_example = 0\n",
    "\n",
    "# Check a summary of a document from the training set\n",
    "print('Training set example:')\n",
    "print(document[training_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary[training_set_example])\n",
    "print('\\nModel written summary:')\n",
    "print(summarize(transformer, document[training_set_example]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15baaa47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "test_set_example = 3\n",
    "\n",
    "# Check a summary of a document from the test set\n",
    "print('Test set example:')\n",
    "print(document_test[test_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary_test[test_set_example])\n",
    "print('\\nModel written summary:')\n",
    "print(summarize(transformer, document_test[test_set_example]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd7ef5",
   "metadata": {},
   "source": [
    "Nếu bạn xem xét kỹ lưỡng kết quả đầu ra của mô hình, bạn có thể nhận thấy một số điều:\n",
    "- Trong tập huấn luyện, đầu ra của mô hình (gần như) giống với đầu ra thực (đã có sau 20 kỷ nguyên và thậm chí còn hơn thế nữa với nhiều kỷ nguyên hơn). Điều này có thể là do tập huấn luyện tương đối nhỏ và mô hình tương đối lớn và do đó đã học thuộc lòng các câu trong tập huấn luyện (trang bị quá mức).\n",
    "- Mặc dù hiệu suất trên tập huấn luyện trông rất tuyệt vời nhưng lại không tốt lắm trên tập kiểm tra. Mô hình phù hợp nhưng không khái quát hóa được. Một lần nữa, một ứng cử viên dễ bị đổ lỗi là tập huấn luyện nhỏ và mô hình tương đối lớn, nhưng có thể có nhiều yếu tố khác.\n",
    "- Xem ví dụ tập kiểm tra 3 và phần tóm tắt của nó. Bạn có thể tóm tắt nó giống như cách nó được viết ở đây không? Đôi khi dữ liệu có thể mơ hồ. Và việc đào tạo **mô hình của bạn chỉ có thể tốt khi dữ liệu của bạn**.\n",
    "\n",
    "Ở đây bạn chỉ sử dụng một tập dữ liệu nhỏ để cho thấy rằng có thể học được điều gì đó trong một khoảng thời gian hợp lý trong một môi trường tương đối nhỏ. Nói chung, các máy biến áp lớn được đào tạo về nhiều nhiệm vụ và trên lượng dữ liệu rất lớn để đạt được hiệu suất vượt trội. Bạn sẽ tìm hiểu thêm về điều này trong phần còn lại của khóa học này."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41014aac",
   "metadata": {},
   "source": [
    "**Chúc mừng bạn đã hoàn thành bài tập tuần này!** Bạn đã làm được rất nhiều việc và bây giờ bạn nên hiểu rõ hơn về Máy biến áp và các khối xây dựng của chúng (bộ mã hóa và bộ giải mã) cũng như cách sử dụng chúng để tóm tắt văn bản. Và hãy nhớ: bạn không cần thay đổi nhiều để sử dụng cùng một mô hình cho người dịch, chỉ cần thay đổi tập dữ liệu và nó sẽ hoạt động!\n",
    "\n",
    "**Cố lên!**"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
